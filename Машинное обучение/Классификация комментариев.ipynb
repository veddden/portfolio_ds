{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект. Классификация комментариев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Необходимо обучить модель классифицировать комментарии на позитивные и негативные. Имеется набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Нужно построить модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "### Инструкция по выполнению проекта\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "### Описание данных\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем необходимые модули и библиотеки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "import numpy as np\n",
    "import re\n",
    "from scipy.sparse import hstack\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "from catboost.text_processing import Tokenizer\n",
    "from sklearn import linear_model\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраним данные в переменной `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изучим информацию о данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "159566  \":::::And for the second time of asking, when ...      0\n",
       "159567  You should be ashamed of yourself \\n\\nThat is ...      0\n",
       "159568  Spitzer \\n\\nUmm, theres no actual article for ...      0\n",
       "159569  And it looks like it was actually you who put ...      0\n",
       "159570  \"\\nAnd ... I really don't think you understand...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143346\n",
       "1     16225\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Пропусков в данных нет. В целевых признаках есть дисбаланс классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраним признаки в переменной `features`, а целевой признак в переменной `target`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data['text']\n",
    "target = data['toxic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим выборки на тренировочную и тестовую в соотношении один к одному, причем используем аргумент `stratify`, чтобы в обеих выборках было одинаковое соотношения классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.5, stratify=target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на размеры выборок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тренировочная выборка (признаки): (79785,)\n",
      "Тестовая выборка (признаки): (79786,)\n",
      "Тренировочная выборка (целевые признаки): (79785,)\n",
      "Тестовая выборка (целевые признаки): (79786,)\n",
      "Соотношение классов в целевых признаках тренировочной выборки:\n",
      " 0    71673\n",
      "1     8112\n",
      "Name: toxic, dtype: int64\n",
      "Соотношение классов в целевых признаках тестовой выборки:\n",
      " 0    71673\n",
      "1     8113\n",
      "Name: toxic, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Тренировочная выборка (признаки):',features_train.shape)\n",
    "print('Тестовая выборка (признаки):',features_test.shape)\n",
    "print('Тренировочная выборка (целевые признаки):',target_train.shape)\n",
    "print('Тестовая выборка (целевые признаки):',target_test.shape)\n",
    "print('Соотношение классов в целевых признаках тренировочной выборки:\\n', target_train.value_counts())\n",
    "print('Соотношение классов в целевых признаках тестовой выборки:\\n', target_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Обучение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Логистическая регрессия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве признаков для обучения логистической регрессии используем величины TF-IDF, которые получим с помощью класса `TfidfVectorizer`. Причем получим эти величины для слов, для символов и для n-gram слов и символов, а затем объединим эти данные в один датасет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tf_idf_word = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    token_pattern=r'\\w{1,}',\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_train_word = count_tf_idf_word.fit_transform(features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_test_word = count_tf_idf_word.transform(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tf_idf_char = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='char',\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_train_char = count_tf_idf_char.fit_transform(features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_test_char = count_tf_idf_char.transform(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tf_idf_char_wb = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='char_wb',\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_train_char_wb = count_tf_idf_char_wb.fit_transform(features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_test_char_wb = count_tf_idf_char_wb.transform(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединяем получившиеся данные тренировочную и тестовую выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_train = hstack([tf_idf_train_char, tf_idf_train_word, tf_idf_train_char_wb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_test = hstack([tf_idf_test_char, tf_idf_test_word, tf_idf_test_char_wb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на размеры получившихся выборок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тренировочная выборка: (79785, 146788)\n",
      "Тестовая выборка: (79786, 146788)\n"
     ]
    }
   ],
   "source": [
    "print('Тренировочная выборка:', tf_idf_train.shape)\n",
    "print('Тестовая выборка:', tf_idf_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим линейную регрессию и посчтитаем метрику F1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='liblinear', penalty='l1').fit(tf_idf_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(tf_idf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 = 0.79\n"
     ]
    }
   ],
   "source": [
    "F1 = f1_score(pred, target_test)\n",
    "print('F1 = {:.2f}'.format(F1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 SGDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем также модель SGDClassifier. Подберем параметры с помощью итератора `product`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = product([{'tol':0.001}, {'tol':0.0001},],\n",
    "              [{'eta0':0.01},{'eta0':0.02},{'eta0':0.03},{'eta0':0.04}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tol': 0.001}\n",
      "{'tol': 0.001}\n",
      "{'tol': 0.001}\n",
      "{'tol': 0.001}\n",
      "{'tol': 0.0001}\n",
      "{'tol': 0.0001}\n",
      "{'tol': 0.0001}\n",
      "{'tol': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "buf = dict() # создаем словарь для сохранения результата\n",
    "\n",
    "for i in gen:\n",
    "    print(i[0])\n",
    "   \n",
    "    model = linear_model.SGDClassifier(**i[0], **i[1], alpha=0.000001,\n",
    "                                       random_state=12345, learning_rate='adaptive')\n",
    "    \n",
    "    model.fit(tf_idf_train, target_train)\n",
    "    \n",
    "    pred = model.predict(tf_idf_test)\n",
    "    F1 = f1_score(pred, target_test)\n",
    "    \n",
    "    # Записываем результат вычисления метрики в словарь\n",
    "    buf[str(i)] = 'F1 = {:.2f}'.format(F1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим что получилось."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"({'tol': 0.001}, {'eta0': 0.01})\": 'F1 = 0.78',\n",
       " \"({'tol': 0.001}, {'eta0': 0.02})\": 'F1 = 0.79',\n",
       " \"({'tol': 0.001}, {'eta0': 0.03})\": 'F1 = 0.80',\n",
       " \"({'tol': 0.001}, {'eta0': 0.04})\": 'F1 = 0.80',\n",
       " \"({'tol': 0.0001}, {'eta0': 0.01})\": 'F1 = 0.79',\n",
       " \"({'tol': 0.0001}, {'eta0': 0.02})\": 'F1 = 0.79',\n",
       " \"({'tol': 0.0001}, {'eta0': 0.03})\": 'F1 = 0.79',\n",
       " \"({'tol': 0.0001}, {'eta0': 0.04})\": 'F1 = 0.78'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель на оптимальных гиперпараметрах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = linear_model.SGDClassifier(tol=0.001, eta0=0.04, alpha=0.000001, \n",
    "                                   random_state=12345, learning_rate='adaptive').fit(tf_idf_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(tf_idf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 = 0.80\n"
     ]
    }
   ],
   "source": [
    "F1 = f1_score(pred, target_test)\n",
    "print('F1 = {:.2f}'.format(F1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 CatBoost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем модель CatBoost Classifier. Для того, чтобы передать аргумент `text_features`, создадим датафреймы обучающей и тестовой выборок с колонками *'text'*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = pd.DataFrame(data=features_train, columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = pd.DataFrame(data=features_test, columns=['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию `fit_catboost`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_catboost(X_train, X_test, y_train, y_test, catboost_params={}, verbose=100):\n",
    "    \n",
    "    # используем конструктор Pool для создания обучающей и тестовой выборки, обозначаем текстовые данные\n",
    "    learn_pool = Pool(\n",
    "        X_train, \n",
    "        y_train, \n",
    "        text_features=['text'],\n",
    "    )\n",
    "    test_pool = Pool(\n",
    "        X_test, \n",
    "        y_test, \n",
    "        text_features=['text'],\n",
    "    )\n",
    "    \n",
    "    # задаем гиперпараметры по умолчанию\n",
    "    catboost_default_params = {\n",
    "        'iterations': 1000,\n",
    "        'learning_rate': 0.03,\n",
    "        'eval_metric': 'F1',\n",
    "        'task_type': 'GPU'\n",
    "    }\n",
    "    \n",
    "    # обновляем дефолтные параметры параметрами из catboost_params\n",
    "    catboost_default_params.update(catboost_params)\n",
    "    \n",
    "    # создаем и обучаем модель\n",
    "    model = CatBoostClassifier(**catboost_default_params)\n",
    "    model.fit(learn_pool, eval_set=test_pool, verbose=verbose)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: less than 75% gpu memory available for training. Free: 1198.8125 Total: 1996.8125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6677586\ttest: 0.6990667\tbest: 0.6990667 (0)\ttotal: 152ms\tremaining: 2m 31s\n",
      "100:\tlearn: 0.6689785\ttest: 0.6988283\tbest: 0.7026839 (6)\ttotal: 11.6s\tremaining: 1m 43s\n",
      "200:\tlearn: 0.6822838\ttest: 0.7072821\tbest: 0.7079215 (189)\ttotal: 23s\tremaining: 1m 31s\n",
      "300:\tlearn: 0.6916398\ttest: 0.7146937\tbest: 0.7148669 (299)\ttotal: 33.4s\tremaining: 1m 17s\n",
      "400:\tlearn: 0.6972069\ttest: 0.7164669\tbest: 0.7169165 (383)\ttotal: 43.7s\tremaining: 1m 5s\n",
      "500:\tlearn: 0.7027844\ttest: 0.7175899\tbest: 0.7176303 (492)\ttotal: 53.6s\tremaining: 53.4s\n",
      "600:\tlearn: 0.7064591\ttest: 0.7174830\tbest: 0.7177143 (547)\ttotal: 1m 3s\tremaining: 42.2s\n",
      "700:\tlearn: 0.7098031\ttest: 0.7188103\tbest: 0.7189019 (699)\ttotal: 1m 13s\tremaining: 31.4s\n",
      "800:\tlearn: 0.7125658\ttest: 0.7187589\tbest: 0.7189019 (699)\ttotal: 1m 23s\tremaining: 20.7s\n",
      "900:\tlearn: 0.7149458\ttest: 0.7196796\tbest: 0.7199028 (882)\ttotal: 1m 33s\tremaining: 10.2s\n",
      "999:\tlearn: 0.7170111\ttest: 0.7195540\tbest: 0.7199600 (985)\ttotal: 1m 42s\tremaining: 0us\n",
      "bestTest = 0.7199599943\n",
      "bestIteration = 985\n",
      "Shrink model to first 986 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f05f1535690>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_catboost(\n",
    "    features_train,\n",
    "    features_test, \n",
    "    target_train, \n",
    "    target_test,\n",
    "    \n",
    "    # подбираем параметры для преобразования текстовых данных в числовые\n",
    "    catboost_params={\n",
    "        'text_processing': {\n",
    "            # делаем токенизацию по словам и знакам пунктуации\n",
    "            \"tokenizers\" : [{\n",
    "                \"tokenizer_id\" : \"Space\",\n",
    "                \"delimiter\" : \" \",\n",
    "                \"lowercasing\" : \"true\"\n",
    "                },{\n",
    "                \"tokenizer_id\" : \"Punc\",\n",
    "                \"delimiter\" : \" \",\n",
    "                \"lowercasing\" : \"true\",\n",
    "                \"token_types\" : \"Punctuation\"\n",
    "            }],\n",
    "            \n",
    "            # создаем словари из 1-, 2- и 3-грамм \n",
    "            \"dictionaries\" : [{\n",
    "                \"dictionary_id\" : \"BiGram\",\n",
    "                \"gram_order\" : \"2\"\n",
    "            },{\n",
    "                \"dictionary_id\" : \"Word\",\n",
    "                \"gram_order\" : \"1\"\n",
    "            },{\n",
    "                \"dictionary_id\" : \"ThreeGram\",\n",
    "                \"gram_order\" : \"3\"\n",
    "            }\n",
    "            ],\n",
    "            \n",
    "            # применяем модели BoW NaiveBayes BM25 для создания числовых данных\n",
    "            \"feature_processing\" : {\n",
    "                \"default\" : [{\n",
    "                    \"dictionaries_names\" : [\"Word\", \"BiGram\", \"ThreeGram\"],\n",
    "                    \"feature_calcers\" : [\"BoW\", 'NaiveBayes', \"BM25\"],\n",
    "                    \"tokenizers_names\" : [\"Space\", \"Punc\"]\n",
    "                    }]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе проекта удалось достичь значения метрики F1 = 0.8 на обучении модели SGDClassifier. В модели CatBoost удалось достичь значения метрики 0.72, но на вход подавался необработанный текст.\n",
    "\n",
    "------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
